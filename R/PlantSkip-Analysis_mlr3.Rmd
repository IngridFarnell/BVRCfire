---
title: "FourFires-Analysis_mlr"
author: "Ingrid Farnell & Alana Clason"
date: "25/02/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

This script runs ranger using mlr3 package
More info: https://mlr3book.mlr-org.com/introduction.html

Overall data flow:
Step 1: Prepare data
Step 2: Define spatial task
Step 3: Define learner (ranger classification)
Step 4: Separate task into learning (80%) and test (20%) datasets
Step 5: Optimize learner variable importance using spatial cross fold validation
Step 6: Train learner on training data
Step 7: Predict test data using trained learner
Step 8: Evaluate model on test data
Step 9: Visualize 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#------------------------------ Load libraries---------------------------------#
ls <- c("tidyverse", "data.table", "magrittr") # Data Management and Manipulation
ls <- append(ls, c("raster")) # geo comp.
ls <- append(ls, c("pdp", "mlr3", "mlr3spatiotempcv", "mlr3verse", "vegan", "corrplot")) # analysis
ls <- append(ls, c("iml", "patchwork", "DALEX", "DALEXtra","wesanderson")) # model interpretation/visualization

# Install if needed -- then load. 
new.packages <- ls[!(ls %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(ls, library, character.only = TRUE)  # load the required packages
rm(ls, new.packages)


#------------------------------ 1. Load data ----------------------------------#
#SpatialFilesPath <- "E:/Ingrid/Borealis/BVRCfire"
SpatialFilesPath <- getwd()
# Set the fires of interest - all 2018 fires with openings
FiresOfInterest <- c("G41607", "G51632", "R11498", "R11796","R11921","R21721")


# Read in the rasters
variable_list <- list.files(paste0(SpatialFilesPath, "/Inputs/Rasters/"),
                            pattern =  paste(FiresOfInterest, sep = "", collapse = "|"),
                            recursive = TRUE,
                            full.names = TRUE)
variable_list <- grep("tif", variable_list, value=TRUE)
# Drop OpenID, None and SitePrepped
variable_list <- grep("OpenID|None|SitePrepped|n83", variable_list, value = TRUE, invert = TRUE)
# For now remove this one because the raster contains only NA's -- Alana to fix and then remove this line
variable_list <- grep("R11498_SpotBurn", variable_list, value = TRUE, invert = TRUE)
variable_list <- c(variable_list,paste0(SpatialFilesPath,"/Inputs/Rasters/Topography/DEM",
                                        c("aspect","hli","slope","tpi"),".tif"))

variables <- sapply(variable_list, raster)


# Rename the variables 
variable.name <- lapply(str_split(variable_list,"/"), function(x) grep(".tif", x, value=TRUE))
variable.name <- str_split(variable.name, ".tif", simplify = TRUE)[,1]

names(variables) <- variable.name

#ID the names of the categorical rasters
ctg_variables <- c("BEC", "BroadBurn", "Brushed", "DebrisMade", "DebrisPiled", "Fertil", "MechUnk", 
                   "OPENING_ID", "PileBurn", "Prune", "Soil", "Spaced", 
                   "SpotBurn", "WBurn")
CatRasts <- grep(paste(ctg_variables,sep = "", collapse = "|"),variable.name,value=TRUE)

```

Prepare the data:
- Resample response and predictor variables to have the same extent and resolution (30 x 30 m) for each of the fires. 
-     Categorical variables are resampled using nearest neighbourhood and continuous variables are resampled using bilinear resampling.
- Subsample at 270-m grid spacing to reduce spatial autocorrelation
- Data must be free of NAs 
- Data must not have variables with no variance


```{r, include = FALSE, warning = FALSE}
# ------------------------------Prepare data-----------------------------------#
#--------------------------2a. Resample rasters and stack----------------------#

# Using base rasters resample response and predictor variables to same extent and resolution
for(i in 1:length(FiresOfInterest)){
  allFireRasts <- variables[c(grep(FiresOfInterest[i],variables),grep("DEM",variables))]
  baseFireRast <- allFireRasts[grep("Base",allFireRasts)][[1]] #index just makes it not a list
  allFireRasts <- allFireRasts[grep("Base",allFireRasts,invert=TRUE)]
  
  # Resample categorical and continuous variables differently
  a <- list()
  for(j in 1:length(allFireRasts)){
    if(names(allFireRasts[[j]]) %in% CatRasts){
      a[[j]] <- raster::resample(allFireRasts[[j]], baseFireRast, method = "ngb")
    } else {
      a[[j]] <- raster::resample(allFireRasts[[j]], baseFireRast, method = "bilinear")
    }
  }
  fireID <- str_extract(names(allFireRasts[1]),FiresOfInterest[i])
  SimpleRastnames <- str_remove(str_remove(names(allFireRasts),FiresOfInterest[i]),"_")
  names(a) <- SimpleRastnames
  #stack the simplified names and assign to fire id rast name
  assign(paste0(fireID,"rasts"), stack(a))
}


#-----------------------------2b. Get sample points----------------------------#
# Create index of raster stacks
RastStacks <- list(G41607rasts, G51632rasts, R11498rasts, R11796rasts, R11921rasts, R21721rasts)

for(i in 1:length(FiresOfInterest)){
  allFireRasts <- variables[grep(FiresOfInterest[i],variables)]
  dNBRFireRast <- allFireRasts[grep("dNBR",allFireRasts)][[1]] #use a raster (doesn't matter which one)
  
  # 270 m grid distance
  b <- aggregate(dNBRFireRast, fact = 9, fun = mean)
  points270 <- rasterToPoints(b, spatial = TRUE) # get sample grid: 1 point/270 m, spatial = TRUE so coordinates are attached
  colnames(points270@data) <- "drop" # make sure to drop this later on(it's a place holder column for points)
  
  # Extract response and predictor values at sample points
  SampledRaster <- raster::extract(RastStacks[[i]], points270, sp = TRUE)
  # Convert to data frame
  dat270 <- as.data.frame(SampledRaster) # hopefully xy = TRUE will attach coordinates, if not do sp = TRUE in above extract line
  
  # Drop rows that don't have an opening ID because we only want to include plantation openings
  dat270 <- dat270 %>% filter(!is.na(OPENING_ID))
  # Drop opening ID column
  dat270 <- subset(dat270, select =-c(OPENING_ID, drop))
  
  # Meet spatial RF requirements
  # 1. Must be free of NA
  dat270 <- dat270[complete.cases(dat270), ] # remove NAs
  
  # 2. Columns cannot have 0 variance
  RemoveZeroVar <- function(dat270) {
    dat270[, !sapply(dat270, function(x) min(x) == max(x))]
  }
  dat270 <- RemoveZeroVar(dat270)
  
  # 3. Columns must not yield NaN or Inf when scaled
  #sum(apply(scale(R11796dat270), 2, is.nan)) 
  #sum(apply(scale(R11796dat270), 2, is.infinite))
  # Find which columns are giving issue
  #sapply(as.data.frame(scale(R21721_270)), function(x)any(is.nan(x)))
  
  # Move response (dNBR) to first column
  dat270 <- dat270 %>% dplyr::select("dNBR", everything())
  fireID <- str_extract(names(allFireRasts[1]),FiresOfInterest[i])
  assign(paste0(fireID,"dat270"), dat270)
  
}
#watch - order is hard coded
list_dats <- list(G41607dat270,G51632dat270,R11498dat270,R11796dat270,R11921dat270,R21721dat270)
FiresOfInterest
for(ii in 1:length(list_dats)){
  write.csv(list_dats[[ii]],paste0("./Inputs/",FiresOfInterest[ii],"dat270.csv"),row.names = FALSE)
}

```


Load the above data that I saved to my computer (for faster processing)
Load data as sf object
- scale dNBR *1000
- set fire history == 0 to 100
- add principal coordinate analysis variables to predictors
```{r, include=FALSE}
ctg_variables <- c("BEC", "BroadBurn", "Brushed", "DebrisMade", "DebrisPiled", "Fertil", "MechUnk", 
                   "OPENING_ID", "PileBurn", "Prune", "Soil", "Spaced", 
                   "SpotBurn", "WBurn","dNBRCAT")
datPath <- "C:/Users/farne/Documents/" #"./Inputs/"   


Chutanli <- fread(paste0(datPath,"G41607dat270.csv"))
Chutanli <- Chutanli %>%
  mutate_at((colnames(Chutanli)[colnames(Chutanli) %in% ctg_variables]), factor) %>%
  dplyr::select(-c("dNBRReSamp")) #can remove if you remembered to save without row.names
Chutanli[,dNBR := dNBR*1000]
Chutanli[HistoricFires==0 ,HistoricFires:=100]
Chutanli_dist <- dist(Chutanli[,.(x,y)], method = "euclidean")
Chutanli_pcnm <- pcnm(Chutanli_dist)
Chutanli[, c("PCNM1","PCNM2", "PCNM3",
             "PCNM4", "PCNM5","PCNM6") := .(Chutanli_pcnm$vectors[,"PCNM1"],
                                            Chutanli_pcnm$vectors[,"PCNM2"],
                                            Chutanli_pcnm$vectors[,"PCNM3"],
                                            Chutanli_pcnm$vectors[,"PCNM4"],
                                            Chutanli_pcnm$vectors[,"PCNM5"],
                                            Chutanli_pcnm$vectors[,"PCNM6"])]

Tezzeron <- fread(paste0(datPath,"G51632dat270.csv"))
Tezzeron <- Tezzeron %>%
  mutate_at((colnames(Tezzeron)[colnames(Tezzeron) %in% ctg_variables]), factor)%>%
  dplyr::select(-c("dNBRReSamp"))
Tezzeron[,dNBR := dNBR*1000]
#Tezzeron[HistoricFires==0 ,Tezzeron:=100] # no historic fires
Tezzeron_dist <- dist(Tezzeron[,.(x,y)], method = "euclidean")
Tezzeron_pcnm <- pcnm(Tezzeron_dist)
Tezzeron[, c("PCNM1","PCNM2", "PCNM3",
             "PCNM4", "PCNM5","PCNM6") := .(Tezzeron_pcnm$vectors[,"PCNM1"],
                                            Tezzeron_pcnm$vectors[,"PCNM2"],
                                            Tezzeron_pcnm$vectors[,"PCNM3"],
                                            Tezzeron_pcnm$vectors[,"PCNM4"],
                                            Tezzeron_pcnm$vectors[,"PCNM5"],
                                            Tezzeron_pcnm$vectors[,"PCNM6"])]

Shovel <- fread(paste0(datPath,"R11498dat270.csv"))
Shovel <- Shovel %>%
  mutate_at((colnames(Shovel)[colnames(Shovel) %in% ctg_variables]), factor)%>%
  dplyr::select(-c("dNBRReSamp"))
Shovel[,dNBR := dNBR*1000]
Shovel[HistoricFires==0 ,HistoricFires:=100]
Shovel_dist <- dist(Shovel[,.(x,y)], method = "euclidean")
Shovel_pcnm <- pcnm(Shovel_dist)
Shovel[, c("PCNM1","PCNM2", "PCNM3",
             "PCNM4", "PCNM5","PCNM6") := .(Shovel_pcnm$vectors[,"PCNM1"],
                                            Shovel_pcnm$vectors[,"PCNM2"],
                                            Shovel_pcnm$vectors[,"PCNM3"],
                                            Shovel_pcnm$vectors[,"PCNM4"],
                                            Shovel_pcnm$vectors[,"PCNM5"],
                                            Shovel_pcnm$vectors[,"PCNM6"])]

Verdun <- fread(paste0(datPath,"R11796dat270.csv"))
Verdun <- Verdun %>%
  mutate_at((colnames(Verdun)[colnames(Verdun) %in% ctg_variables]), factor)%>%
  dplyr::select(-c("dNBRReSamp"))
Verdun[,dNBR := dNBR*1000]
Verdun[HistoricFires==0 ,HistoricFires:=100]
Verdun_dist <- dist(Verdun[,.(x,y)], method = "euclidean")
Verdun_pcnm <- pcnm(Verdun_dist)
Verdun[, c("PCNM1","PCNM2", "PCNM3",
             "PCNM4", "PCNM5","PCNM6") := .(Verdun_pcnm$vectors[,"PCNM1"],
                                            Verdun_pcnm$vectors[,"PCNM2"],
                                            Verdun_pcnm$vectors[,"PCNM3"],
                                            Verdun_pcnm$vectors[,"PCNM4"],
                                            Verdun_pcnm$vectors[,"PCNM5"],
                                            Verdun_pcnm$vectors[,"PCNM6"])]

Island <- fread(paste0(datPath,"R11921dat270.csv"))
Island <- Island %>%
  mutate_at((colnames(Island)[colnames(Island) %in% ctg_variables]), factor)%>%
  dplyr::select(-c("dNBRReSamp"))
Island[,dNBR := dNBR*1000]
Island[HistoricFires==0 ,HistoricFires:=100]
Island_dist <- dist(Island[,.(x,y)], method = "euclidean")
Island_pcnm <- pcnm(Island_dist)
Island[, c("PCNM1","PCNM2", "PCNM3",
             "PCNM4", "PCNM5","PCNM6") := .(Island_pcnm$vectors[,"PCNM1"],
                                            Island_pcnm$vectors[,"PCNM2"],
                                            Island_pcnm$vectors[,"PCNM3"],
                                            Island_pcnm$vectors[,"PCNM4"],
                                            Island_pcnm$vectors[,"PCNM5"],
                                            Island_pcnm$vectors[,"PCNM6"])]

Nadina <- fread(paste0(datPath,"R21721dat270.csv"))
Nadina <- Nadina %>%
  mutate_at((colnames(Nadina)[colnames(Nadina) %in% ctg_variables]), factor)%>%
  dplyr::select(-c("dNBRReSamp"))
Nadina[,dNBR := dNBR*1000]
Nadina[HistoricFires==0 ,HistoricFires:=100]
Nadina_dist <- dist(Nadina[,.(x,y)], method = "euclidean")
Nadina_pcnm <- pcnm(Nadina_dist)
Nadina[, c("PCNM1","PCNM2", "PCNM3",
             "PCNM4", "PCNM5","PCNM6") := .(Nadina_pcnm$vectors[,"PCNM1"],
                                            Nadina_pcnm$vectors[,"PCNM2"],
                                            Nadina_pcnm$vectors[,"PCNM3"],
                                            Nadina_pcnm$vectors[,"PCNM4"],
                                            Nadina_pcnm$vectors[,"PCNM5"],
                                            Nadina_pcnm$vectors[,"PCNM6"])]

#ordisurf(Chutanli_xy, scores(Chutanli_pcnm, choices=1), bubble = 4, main = "PCNM 1")
#plot(Chutanli_pcnm$values) #most the variation is in the first 20 or so eigenvectors

#ggplot()+
 # geom_point(aes(y=Chutanli$dNBR, x= Chutanli_pcnm$vectors[,17]))+
  #geom_smooth(aes(y=Chutanli$dNBR, x= Chutanli_pcnm$vectors[,17]), method="gam")

#create datasets with variables to include in analysis. We are keeping them (cat response and continuous response) as seperate datasets, because it's imbedded in the code below to pass the entire object and not specify which columns to ignore
Chutanli_sf_con <- sf::st_as_sf(Chutanli[,-c("dNBRCAT")], coords = c("x", "y"))
Chutanli_sf_cat <- sf::st_as_sf(Chutanli[,-c("dNBR")], coords = c("x", "y"))

Tezzeron_sf_con <- sf::st_as_sf(Tezzeron[,-c("dNBRCAT")], coords = c("x", "y"))
Tezzeron_sf_cat <- sf::st_as_sf(Tezzeron[,-c("dNBR")], coords = c("x", "y"))

Shovel_sf_con <- sf::st_as_sf(Shovel[,-c("dNBRCAT")], coords = c("x", "y"))
Shovel_sf_cat <- sf::st_as_sf(Shovel[,-c("dNBR")], coords = c("x", "y"))

Verdun_sf_con <- sf::st_as_sf(Verdun[,-c("dNBRCAT")], coords = c("x", "y"))
Verdun_sf_cat <- sf::st_as_sf(Verdun[,-c("dNBR")], coords = c("x", "y"))

Island_sf_con <- sf::st_as_sf(Island[,-c("dNBRCAT")], coords = c("x", "y"))
Island_sf_cat <- sf::st_as_sf(Island[,-c("dNBR")], coords = c("x", "y"))

Nadina_sf_con <- sf::st_as_sf(Nadina[,-c("dNBRCAT")], coords = c("x", "y"))
Nadina_sf_cat <- sf::st_as_sf(Nadina[,-c("dNBR")], coords = c("x", "y"))

```


test highly correlated variables
```{r}
#--- Assess correlated covariates
plot <- list()
corrT <- list()
task_names <- c("Chutlani","Nadina","Shovel","Island","Verdun","Tezzeron")
dat_names <- list(Chutanli,Nadina,Shovel,Island,Verdun,Tezzeron)

for(i in 1:length(dat_names)){
  dat <- as.data.table(dat_names[[i]])
  dat <- dat %>% select_if(is.numeric)
  
  corrMat <- round(cor(dat, method="spearman"), 2)

  plot[[i]] <- corrplot(corrMat, 
                        title = paste0(task_names[i]))
  # 0.7 cutoff
  corr <- as.data.frame(corrMat)
  corr[abs(corr) < .7 & abs(corr) < 1] <- ""
  write.csv(corr, paste0(datPath, task_names[i], "corr.csv"))
}
#keep dmc, fwi. Drop dc, isi
```


Benchmarking - tasks with different fire weather variables dropped
```{r benchmark, echo=FALSE}
task_names <- c("Chutlani","Nadina","Shovel","Island","Verdun","Tezzeron")
dat_list <- list(Chutanli_sf_cat, Nadina_sf_cat, Shovel_sf_cat, Island_sf_cat,
                 Verdun_sf_cat, Tezzeron_sf_cat)
tab <- list()
NumCores <- 20
for(i in 1:length(task_names)){
  # Remove correlated covariates
  dat <- dat_list[[i]]
  dat.1 <- dplyr::select(dat, -dob, -bui, -dc, -isi) #keep dmc, fwi
  dat.2 <- dplyr::select(dat, -dob, -bui, -dmc, -isi) #keep dc, fwi
  dat.3 <- dplyr::select(dat, -dob, -dc, -dmc, -isi) #keep bui, fwi
  dat.4 <- dplyr::select(dat, -dob, -bui, -dc, -fwi) #keep dmc, isi
  dat.5 <- dplyr::select(dat, -dob, -bui, -dmc, -fwi) #keep dc, isi
  dat.6 <- dplyr::select(dat, -dob, -dc, -dmc, -fwi) #keep bui, isi

  
  task.1 <- TaskClassifST$new(task_names[i],
                         backend = dat.1, 
                         target = "dNBRCAT")

  task.2 <- TaskClassifST$new(task_names[i],
                         backend = dat.2, 
                         target = "dNBRCAT")
  task.3 <- TaskClassifST$new(task_names[i],
                         backend = dat.3, 
                         target = "dNBRCAT")
  task.4 <- TaskClassifST$new(task_names[i],
                         backend = dat.4, 
                         target = "dNBRCAT")
  task.5 <- TaskClassifST$new(task_names[i],
                         backend = dat.5, 
                         target = "dNBRCAT")
  task.6 <- TaskClassifST$new(task_names[i],
                         backend = dat.6, 
                         target = "dNBRCAT")
  
  tasks <- list(task.1, task.2, task.3, task.4, task.5, task.6)
  
  #--- Step 2: Define a learner
  # default ranger parameters: https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.ranger.html
  learner <- lrn("classif.ranger",
                importance = "permutation",
                respect.unordered.factors = "order",
                predict_type = "response",
                num.threads=NumCores)

  
  #--- Step 3: Feature selection & task benchmarking (using nested resampling)
  measure <- msr("classif.ce") #classification error
  fselector <- fs("random_search", batch_size=20) # using random_search b/c of large search space
  #level = 0.2 
  #terminator = trm("perf_reached", level=level)
  #terminator = trm("stagnation", iters=40, threshold=0)
  terminator <- trm("evals", n_evals=20)
  inner_resampling <- rsmp("spcv_coords", folds=5)
  outer_resampling <- rsmp("spcv_coords", folds=5)
  
  # Feature selection
  optFtlrn <- AutoFSelector$new(
    learner = learner,
    resampling = inner_resampling,
    measure = measure,
    terminator = terminator,
    fselector = fselector
  )
  
  # Task benchmarking
  grid <- benchmark_grid(
    tasks = tasks,
    learner = optFtlrn,
    resampling = outer_resampling
  )
  
  # Apply optimal learner and benchmarking
  set.seed(456)
  bmr <- benchmark(grid, store_models = TRUE)
  
  measure <- msr("classif.ce")
  
  #--- Compare all tasks 
  tab[[i]] <- bmr$aggregate(measure)

} 
for(i in 1:6){
  tab[[i]][,FireID := task_names[i]]
}
tab_dt <- rbindlist(tab)

#which nr is the min for each fire?
tab_dt[,.SD[which.min(classif.ce)], by=.(FireID)]

#which is the most common? 5 or 6.

#select 5?

```


RF analysis (multicorrilated variables are dropped, model is tuned for top pred variables)
```{r}
task_names <- c("Chutanli","Nadina","Shovel","Island","Verdun","Tezzeron")
dat_list <- list(Chutanli_sf_cat, Nadina_sf_cat, Shovel_sf_cat, Island_sf_cat,
                 Verdun_sf_cat, Tezzeron_sf_cat)
#CV_Conf <- list()
Test_Conf <- list()
TrainImp_dat <- list()
RF_scores <- list()
pd_scores <- list()
effects <- list()
NumCores <- 30

for(i in 1:length(task_names)){
  # Remove correlated covariates
  dat <- dat_list[[i]]
  dat <- dplyr::select(dat, -dob, -bui, -dmc, -fwi) #keep dc, isi
  
  task <- TaskClassifST$new(task_names[i],
                         backend = dat, 
                         target = "dNBRCAT")
  
  #--- Step 1: Define a learner
  # default ranger parameters: https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.ranger.html
  learner <- lrn("classif.ranger",
                importance = "permutation",
                respect.unordered.factors = "order",
                predict_type = "response",
                num.trees = 2000,
                num.threads=NumCores)
  
  #--- Step 2: Split stratified task into test/train data
  set.seed(456)
  split <- partition(task, ratio=0.8, stratify=TRUE)
  task_train <- task$clone()$filter(rows=split$train)
  task_test <- task$clone()$filter(rows=split$test)
  
  #--- Step 3: Feature selection (using nested resampling)
  measure <- msr("classif.ce") #classification error
  fselector <- fs("random_search", batch_size = 30)
  terminator <- trm("evals", n_evals=100)
  inner_resampling <- rsmp("spcv_coords", folds=5)
   
  optFtlrn = AutoFSelector$new(
    learner = learner,
    resampling = inner_resampling,
    measure = measure,
    terminator = terminator,
    fselector = fselector
  )
  
  #--- Step 4: Train final model (applies tuning)
  set.seed(456)
  optFtlrn$train(task_train) 
  
  #--- Step 5: Predict on test data
  optFtlrnPred <- optFtlrn$predict(task_test) 
  optFtlrnPred$score(measure)
  
  #trained model predictions
  #optFtlrnPred$prob
  Test_Conf[[i]] <- optFtlrnPred$confusion
  RF_scores[[i]] <- optFtlrnPred$score()
  
  #--- Step 6: Model visualization
  # Feature importance
  TrainImp_dat[[i]] <- as.data.table(optFtlrn$learner$importance(), keep.rownames = TRUE)
  
  # Feature Imp
  #  Level of importance of the features
  dat_train <- task_train$data()
  x_train <- dat_train[,-c("dNBRCAT")]
  
  model <- Predictor$new(optFtlrn, data = x_train, y = dat_train$dNBRCAT)
  effects[[i]] <- FeatureEffects$new(model)
  model_exp = explain_mlr3(optFtlrn,
                         data = x_train, # provide data without y 
                         y = dat_train$dNBRCAT,
                         colorize = FALSE,
                         type="classification")

  pd_scores[[i]] <- model_profile(model_exp)$agr_profiles
  
} 

Test_Conf 
TrainImp_dat 
RF_scores 
pd_scores 
effects 



```


Results figures
```{r}
########### results

#my attempt to make that multi-fire graph:
for(i in 1:6){
  TrainImp_dat[[i]][,FireID := task_names[i]]
}
TrainImp_dt <- rbindlist(TrainImp_dat)
setnames(TrainImp_dt, c("Variable","Score","FireID"))
TrainImp_dt[,VarCat:=ifelse(Variable =="PlantAge","Forest structure",
                      ifelse(Variable =="BASAL_AREA","Forest structure",
                       ifelse(Variable =="CROWN_CLOS","Forest structure",
                        ifelse(Variable =="HistoricFires","Forest structure",
                         ifelse(Variable =="DFirCov","Forest structure",
                          ifelse(Variable =="SpruceCov","Forest structure",
                           ifelse(Variable =="FirCov","Forest structure",
                            ifelse(Variable =="decidCov","Forest structure",
                             ifelse(Variable =="PineCov","Forest structure",
                               ifelse(Variable =="PCNM1","Spatial",
                                ifelse(Variable =="PCNM2","Spatial",
                                 ifelse(Variable =="PCNM3","Spatial",
                                  ifelse(Variable =="PCNM4","Spatial",
                                   ifelse(Variable =="PCNM5","Spatial",
                                    ifelse(Variable =="DEMslope","Climate-Topography",
                                     ifelse(Variable =="DEMhli","Climate-Topography",
                                      ifelse(Variable =="DEMaspect","Climate-Topography",
                                       ifelse(Variable =="BEC","Climate-Topography",
                                       ifelse(Variable =="dc","Fire weather",
                                        ifelse(Variable =="isi","Fire weather",
                                         ifelse(Variable =="maxT","Fire weather",
                                          ifelse(Variable =="maxRH","Fire weather",
                                           ifelse(Variable =="maxW","Fire weather",
                                            ifelse(Variable =="FireRun","Fire weather",
                                              "Silviculture"))))))))))))))))))))))))]
colVar <- unique(TrainImp_dt[,.(Variable,VarCat)])


#doesn't work because of ordering
colVar[,VarCatCol:=ifelse(VarCat=="Forest structure", 
                               wes_palette(5,name="Darjeeling1",type="continuous")[][1],
                         ifelse(VarCat=="Spatial", 
                                wes_palette(5,name="Darjeeling1",type="continuous")[][2],
                          ifelse(VarCat=="Climate-Topography",
                                 wes_palette(5,name="Darjeeling1",type="continuous")[][3],
                            ifelse(VarCat=="Fire weather",
                                 wes_palette(5,name="Darjeeling1",type="continuous")[][4],
                                 wes_palette(5,name="Darjeeling1",type="continuous")[][5]))))]
colVar

ggplot(TrainImp_dt, aes(x = Score, y = reorder(VarCat,Score))) +  
  geom_point(aes(colour=FireID), size=3) +
  scale_color_viridis_d(name="Fire",labels=c("Chutanli","Island","Nadina","Shovel","Tezzeron","Verdun"))+
  xlab("Variable importance")+
  ylab("Variable groups")+
  theme_minimal()

ggplot(TrainImp_dt, aes(x = Score, y = reorder(Variable,Score))) +  
  geom_point(aes(colour=FireID), size=3) +
  scale_color_viridis_d(name="Fire",labels=c("Chutanli","Island","Nadina","Shovel","Tezzeron","Verdun"))+
  xlab("Variable importance")+
  ylab("Variable groups")+
  theme_minimal()


ggplot(TrainImp_dt, aes(x = Score, y = reorder(Variable,Score))) +  
  geom_point(aes(colour=FireID), size=2) +
  facet_wrap("FireID")+
  xlab("")

Silvic_Vars <- c("BroadBurn", "Brushed", "DebrisMade", "DebrisPiled", "Fertil", "PileBurn", 
                  "Prune", "Soil", "Spaced", "SpotBurn")

Silv_Imp_dt <- TrainImp_dt[Variable %in% Silvic_Vars]
ggplot(Silv_Imp_dt, aes(x = Score, y = reorder(Variable,Score))) +  
  geom_point(aes(colour=FireID), size=2) +
  xlab("") +
  xlim(c(-0.01,0.2))+
  ylab("Variable Importance")

num_features <- c("PlantAge")

plot(effects[[1]], features = num_features) 
    #scale_y_continuous("Estimated dNBR") +
    ggtitle("Partial Dependence profiles for selected variables")

plot(effects[[1]]$results$PlantAge$.value ~ effects[[1]]$results$PlantAge$.borders)


PD_plantAge <- list() 
for(i in 1:length(effects)){
  PD_plantAge[[i]] <- data.table(effects[[i]]$results$PlantAge)[,FireID := task_names[i]]
}
PD_plantAge_dt <- rbindlist(PD_plantAge)

ggplot(PD_plantAge_dt)+
  geom_line(aes(x=.borders, y=.value, colour = FireID), size=1.5)+
  facet_wrap(".class")

PD_CrownClos <- list() 
for(i in 1:length(effects)){
  PD_CrownClos[[i]] <- data.table(effects[[i]]$results$CROWN_CLOS)[,FireID := task_names[i]]
}
PD_CrownClos_dt <- rbindlist(PD_CrownClos)

ggplot(PD_CrownClos_dt)+
  geom_line(aes(x=.borders, y=.value, colour = FireID), size=1.5)+
  facet_wrap(".class")

PD_Brushed <- list() 
for(i in 1:length(effects)){
  PD_Brushed[[i]] <- data.table(effects[[i]]$results$Brushed)[,FireID := task_names[i]]
}
PD_Brushed_dt <- rbindlist(PD_Brushed)

ggplot(PD_Brushed_dt)+
  geom_point(aes(x=.borders, y=.value, colour = FireID), size=1.5)+
  facet_wrap(".class")

PD_BroadBurn <- list() 
for(i in 1:length(effects)){
  PD_BroadBurn[[i]] <- data.table(effects[[i]]$results$BroadBurn)[,FireID := task_names[i]]
}
PD_BroadBurn_dt <- rbindlist(PD_BroadBurn)

ggplot(PD_BroadBurn_dt)+
  geom_point(aes(x=.borders, y=.value, colour = FireID), size=1.5)+
  facet_wrap(".class")

PD_Soil <- list() 
for(i in 1:5){
  PD_Soil[[i]] <- data.table(effects[[i]]$results$Soil)[,FireID := task_names[i]]
}
PD_Soil_dt <- rbindlist(PD_Soil)

PD_Brushed <- list() 
for(i in 1:5){
  PD_Brushed[[i]] <- data.table(effects[[i]]$results$Brushed)[,FireID := task_names[i]]
}
PD_Brushed_dt <- rbindlist(PD_Brushed)

PD_DebrisPiled <- list() 
for(i in 1:5){
  PD_DebrisPiled[[i]] <- data.table(effects[[i]]$results$DebrisPiled)[,FireID := task_names[i]]
}
PD_DebrisPiled_dt <- rbindlist(PD_DebrisPiled)

PD_PileBurn <- list() 
for(i in 1:5){
  PD_PileBurn[[i]] <- data.table(effects[[i]]$results$PileBurn)[,FireID := task_names[i]]
}
PD_PileBurn_dt <- rbindlist(PD_PileBurn)


ggplot(PD_Soil_dt)+
  geom_point(aes(x=.borders, y=.value, colour = FireID), size=1.5)+
  facet_wrap(".class")

PD_silv <- rbind(PD_BroadBurn_dt, PD_Soil_dt, PD_Brushed_dt,PD_DebrisPiled_dt,PD_PileBurn_dt)

ggplot(PD_silv)+
  geom_jitter(aes(x=.borders, y=.value, colour=FireID), size=3)+
  #facet_wrap(".class")
  facet_grid(c(".feature",".class"))
  ylim(c(-0.02,0.02))


#probability of unburned:
PD_plantAge_dt
PD_CrownClos_dt


```



Relationship between plantation age and dNBR (continuous)

IF -- can we drop this?
```{r}

set.seed(456)

#--- Assess correlated covariates
task_names <- c("Chutlani","Nadina","Shovel","Island","Verdun","Tezzeron")
dat_list <- list(Chutanli_sf_cat, Nadina_sf_cat, Shovel_sf_cat, Island_sf_cat,
                 Verdun_sf_cat, Tezzeron_sf_cat)

datCon_list <- list(Chutanli_sf_con, Nadina_sf_con, Shovel_sf_con, Island_sf_con,
                 Verdun_sf_con, Tezzeron_sf_con)

plot <- list()
corrT <- list()

for(i in 1:length(task_names)){
  dat <- as.data.table(datCon_list[[i]])
  dat <- dat %>% select_if(is.numeric)
  
  corrMat <- round(cor(dat, method="spearman"), 2)

  plot[[i]] <- corrplot(corrMat, 
                        title = paste0(task_names[i]))
  # 0.7 cutoff
  corr <- as.data.frame(corrMat)
  corr[abs(corr) < .7 & abs(corr) < 1] <- ""
  write.csv(corr, paste0(datPath, task_names[i], "corr.csv"))
}


#--- Run model  
CV_Conf <- list()
Test_Conf <- list()
TrainImp_dat <- list()
NumCores <- 20

for(i in 1:length(task_names)){
  # Remove correlated covariates
  dat <- dat_list[[i]]
  dat[,c("dob", "bui", "dc", "isi")] <- list(NULL)

  #--- Step 1: Define a task
  task = TaskClassifST$new(task_names[i],
                         backend = dat, 
                         target = "dNBRCAT")
  
  #--- Step 2: Define a learner
  # default ranger parameters: https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.ranger.html
  learner = lrn("classif.ranger",
                importance = "permutation",
                respect.unordered.factors = "order",
                predict_type = "prob",
                num.threads=NumCores)
  
  #--- Step 3: Split stratified task into test/train data
  split = partition(task, ratio=0.8, stratify=TRUE) 
  
  task_train = task$clone()$filter(rows=split$train)
  task_test = task$clone()$filter(rows=split$test)
  
  #--- Step 4: Feature selection (using nested resampling)
  measure = msr("classif.ce") #classification error
  fselector = fs("random_search") # using random_search b/c of large search space
  level = 0.5 #0.1 Alana can you try 0.1 and see if it works?
  terminator = trm("perf_reached", level=level)
  inner_resampling = rsmp("spcv_coords", folds=5)
   
  optFtlrn = AutoFSelector$new(
    learner = learner,
    resampling = inner_resampling,
    measure = measure,
    terminator = terminator,
    fselector = fselector
  )

  #--- Step 5: Train final model (applies tuning)
  optFtlrn$train(task_train) #I don't see how the tuning is applied here
  #optFtlrn$model
  
  #--- Step 6: Predict on test data & evaluate model
  optFtlrnPred <- optFtlrn$predict(task_test) 
  optFtlrnPred$score(measure)
 
  #trained model predictions
  optFtlrnPred$prob
  
  #confusion matrix:
  Test_Conf[[i]] <- optFtlrnPred$confusion
  
  sum(optFtlrnPred$confusion) # this is on the test data
  
  #it's good at predicting unburned, there is no high severity here
  
  #--- Step 8: Model visualization
  # Feature importance
  TrainImp_dat[[i]] <- as.data.table(optFtlrn$learner$importance(), keep.rownames = TRUE)
  
  # Feature Imp
  #       Level of importance of the features
  #AC: I think we need to pass just the training data?
  #dat_train <- task_train$data()
  #x_train <- dat_train[,-c("dNBRCAT")]
  #dat_test <- task_test$data()
  
  #impFt <- TrainImp_dat[[i]]$Feature
  #model <- Predictor$new(optFtlrn, data = x_train, y = dat_train$dNBRCAT)
  #effect.imp <- FeatureImp$new(model, loss = "ce")
  #effect.imp$plot(features = impFt)
}  
  


#CV_Conf
Test_Conf

ggplot(TrainImp_dat[[4]], aes(x = reorder(V1, V2), y = V2)) +
  geom_col() +
  coord_flip() + 
  xlab("")


#my attempt to make that multi-fire graph:
TrainImp_dat[[1]][,FireID:=task_names[1]]
TrainImp_dat[[2]][,FireID:=task_names[2]]

ggplot(TrainImp_dat[[2]], aes(x = reorder(V1, V2), y = V2)) +
  geom_point() +
  coord_flip() + 
  xlab("")
  
# Merge TrainImp_dat into one datatable
TrainImp_Alldat <- unique(rbindlist(TrainImp_dat, fill=TRUE), by="V1")
TrainImp_Alldat <- TrainImp_Alldat$V1



```

